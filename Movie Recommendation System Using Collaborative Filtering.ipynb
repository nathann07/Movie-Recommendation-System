{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ede392",
   "metadata": {},
   "source": [
    "# Movie Recommendation System Using Collaborative Filtering\n",
    "\n",
    "This notebook demonstrates the development of a recommendation system using collaborative filtering with Singular Value Decomposition (SVD). The model is trained on the MovieLens dataset to predict user ratings and generate personalized movie recommendations. Key steps include data preprocessing, model training, evaluation, and generating top recommendations for individual users.\n",
    "\n",
    "At the end of the notebook, I've added a summary of the project, insights on model performance, and potential future improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ratings data\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Load the movies data\n",
    "movies = pd.read_csv('u.item', sep='|', encoding='latin-1', names=['item_id', 'title'], usecols=[0, 1])\n",
    "\n",
    "# Merge the two datasets on the item_id column\n",
    "data = pd.merge(ratings, movies, on='item_id')\n",
    "\n",
    "# Display the first few rows to display the data structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d24e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the number of records in each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Define a Reader object with the rating scale used in the MovieLens dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data into a Surprise Dataset\n",
    "data = Dataset.load_from_df(train_data[['user_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760344bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Split data within Surprise (again for compatibility with Surprise’s functions)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "svd = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVD model\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13018639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(user_id, n=5):\n",
    "    # Get all unique item IDs\n",
    "    all_items = data.df['item_id'].unique()\n",
    "    \n",
    "    # Get items the user has already rated\n",
    "    rated_items = train_data[train_data['user_id'] == user_id]['item_id'].unique()\n",
    "    \n",
    "    # Filter for items the user hasn't rated yet\n",
    "    unrated_items = [item for item in all_items if item not in rated_items]\n",
    "    \n",
    "    # Predict ratings for unrated items\n",
    "    predictions = [svd.predict(user_id, item) for item in unrated_items]\n",
    "    \n",
    "    # Sort predictions by estimated rating in descending order\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_n = predictions[:n]\n",
    "    return [(pred.iid, pred.est) for pred in top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Get top 5 recommendations for a user\n",
    "user_id = 1  # Replace with any user ID to test it\n",
    "recommendations = get_top_n_recommendations(user_id, n=5)\n",
    "\n",
    "# Display recommendations\n",
    "# print(\"Top Recommendations:\", recommendations)\n",
    "\n",
    "# Map item IDs to movie titles\n",
    "recommended_titles = [(movies.loc[movies['item_id'] == item_id, 'title'].values[0], rating) for item_id, rating in recommendations]\n",
    "print(\"Top Recommended Movies:\", recommended_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=5, threshold=4.0):\n",
    "    # A dictionary mapping user IDs to their top k predictions\n",
    "    user_est_true = {}\n",
    "    for pred in predictions:\n",
    "        if pred.uid not in user_est_true:\n",
    "            user_est_true[pred.uid] = []\n",
    "        user_est_true[pred.uid].append((pred.est, pred.r_ui))\n",
    "    \n",
    "    # Calculate precision and recall for each user\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort by predicted rating in descending order and take the top k\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_k_ratings = user_ratings[:k]\n",
    "        \n",
    "        # Count relevant items in the top-k (true positives)\n",
    "        relevant_items_top_k = sum((true_r >= threshold) for (_, true_r) in top_k_ratings)\n",
    "        recommended_items = len(top_k_ratings)\n",
    "        \n",
    "        # Count all relevant items for the user (not just in the top-k)\n",
    "        relevant_items_total = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Precision and recall calculations\n",
    "        precision = relevant_items_top_k / recommended_items if recommended_items > 0 else 1\n",
    "        recall = relevant_items_top_k / relevant_items_total if relevant_items_total > 0 else 1\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # Average precision and recall\n",
    "    avg_precision = sum(precisions) / len(precisions)\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and recall at k=5\n",
    "avg_precision, avg_recall = precision_recall_at_k(predictions, k=5, threshold=4.0)\n",
    "print(f\"Precision at K: {avg_precision}\")\n",
    "print(f\"Recall at K: {avg_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f533f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display recommendations with titles\n",
    "def display_recommendations(user_id, n=5):\n",
    "    recommendations = get_top_n_recommendations(user_id, n)\n",
    "    recommended_titles = [(movies.loc[movies['item_id'] == item_id, 'title'].values[0], rating) for item_id, rating in recommendations]\n",
    "    print(f\"Top {n} Recommendations for User {user_id}:\")\n",
    "    for title, rating in recommended_titles:\n",
    "        print(f\"{title}: Predicted Rating {rating:.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Display recommendations for a few sample users\n",
    "sample_users = [1, 50, 150]  # Replace with any user IDs you like\n",
    "for user_id in sample_users:\n",
    "    display_recommendations(user_id, n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e902904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recommendations(user_id):\n",
    "    try:\n",
    "        user_id = int(user_id)  # Ensure the user ID is an integer\n",
    "\n",
    "        # Check if user ID exists in the training data\n",
    "        if user_id not in train_data['user_id'].values:\n",
    "            print(\"User ID not found in the dataset. Please enter a valid user ID.\")\n",
    "            return\n",
    "\n",
    "        # Generate recommendations if user ID is valid\n",
    "        recommendations = get_top_n_recommendations(user_id, n=5)\n",
    "        \n",
    "        # Map item IDs to titles\n",
    "        recommended_titles = [(movies.loc[movies['item_id'] == item_id, 'title'].values[0], rating) for item_id, rating in recommendations]\n",
    "        \n",
    "        # Display recommendations\n",
    "        print(f\"\\nTop 5 Recommendations for User {user_id}:\")\n",
    "        for title, rating in recommended_titles:\n",
    "            print(f\"{title}: Predicted Rating {rating:.2f}\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid numeric user ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb993613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A text input and button widget\n",
    "user_id_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter user ID',\n",
    "    description='User ID:',\n",
    "    disabled=False\n",
    ")\n",
    "button = widgets.Button(description=\"Get Recommendations\")\n",
    "\n",
    "# What happens when the button is clicked\n",
    "def on_button_click(b):\n",
    "    show_recommendations(user_id_input.value)\n",
    "\n",
    "# Link the button to the function\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(user_id_input, button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f166ca",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "In this project, I created a recommendation system using collaborative filtering with Singular Value Decomposition (SVD). The system is designed to recommend items (movies, in this case) to users based on their past ratings. Using user-item interactions, the model predicts ratings for items a user hasn't rated, and suggests those with the highest predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee10a3",
   "metadata": {},
   "source": [
    "### Steps Taken\n",
    "1. **Data Loading**: Loaded the MovieLens dataset, containing user-item ratings and movie information.\n",
    "2. **Data Preprocessing**: Merged datasets, checked for missing values, and split the data into training and test sets.\n",
    "3. **Model Selection**: Used the SVD algorithm from the Surprise library for collaborative filtering.\n",
    "4. **Evaluation**: Assessed model accuracy using RMSE, Precision, and Recall.\n",
    "5. **Recommendations**: Generated top N recommendations for individual users based on predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7babde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Dynamic Markdown text for model performance section\n",
    "model_performance_text = f\"\"\"\n",
    "### Model Performance\n",
    "- **Root Mean Squared Error (RMSE)**: The model achieved an RMSE of approximately **{rmse:.3f}** on the test set, indicating an average prediction error of slightly below 1 rating point.\n",
    "- **Precision at K**: The precision at the top 5 recommended items was approximately **{avg_precision:.3f}**, suggesting that around {avg_precision * 100:.1f}% of the top recommendations were relevant to users.\n",
    "- **Recall at K**: The recall at the top 5 recommended items was approximately **{avg_recall:.3f}**, meaning the model retrieved about {avg_recall * 100:.1f}% of the relevant items for each user.\n",
    "\"\"\"\n",
    "\n",
    "# Display the Markdown\n",
    "display(Markdown(model_performance_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf5ef4",
   "metadata": {},
   "source": [
    "### Future Improvements\n",
    "- **Experiment with Hybrid Models**: Combining collaborative and content-based filtering could provide more personalized recommendations.\n",
    "- **Incorporate Additional Features**: Including genre or timestamp data could help improve predictions for new users.\n",
    "- **Parameter Tuning**: Fine-tuning the SVD model’s parameters might yield better accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
